### [üá∏üá™ Svenska](README.md) / [üá¨üáß English](README_en.md)

# Kubernetes kluster med Metallb som Lastbalanserare
## Introduktion

### Bakgrund

Jag brukar ofta skapa en komplett labbmilj√∂ p√• min egen laptop med hj√§lp av VMware Workstation, d√§r jag s√§tter upp olika virtuella maskiner f√∂r att genomf√∂ra testprojekt eller f√∂rverkliga id√©er. Nu har jag f√•tt m√∂jlighet att s√§tta upp en frist√•ende VMware ESXi-server och blev d√§rf√∂r *tvungen* att bygga ett Kubernetes-kluster samt konfigurera en *LoadBalancer* ist√§llet f√∂r att anv√§nda `kubectl port-forward service`.

### Sammanfattning

Att enbart f√∂lja en av dessa artiklar skulle inte ha hj√§lpt mig att uppn√• mitt m√•l, vilket var att exponera de tj√§nster jag skapar i mitt Kubernetes-kluster externt via en lastbalanserare.

H√§r har jag sammanst√§llt de artiklar jag anv√§nde, tillsammans med en kort beskrivning av hur jag gick tillv√§ga. Allt √§r fr√§mst skrivet f√∂r att hj√§lpa mitt gl√∂mska jag att komma ih√•g processen ‚Äì men om det kan vara till nytta f√∂r dig, s√• vars√•god och anv√§nd det!

###  Labbmilj√∂ 

Labbmilj√∂n bestod av ett Kubernetes-kluster med tre noder, d√§r varje nod var en virtuell maskin som k√∂rde Ubuntu 20.04. Allt detta drevs p√• en frist√•ende ESXi-server, version 8.
### Uppdatering
<aside>
üí° Det fungerade ocks√• bra med VMware Workstation 17 Pro i Windows 10. Det som kr√§vdes var √•terigen att adress-poolen i LBs konfiguration inte kolliderade med vad DHCP ( i VMware Workstation) delade ut.
</aside>

### Referenser

 https://metallb.universe.tf/installation

https://blog.andreev.it/2023/10/install-metallb-on-kubernetes-cluster-running-on-vmware-vms-or-bare-metal-server

https://akyriako.medium.com/load-balancing-with-metallb-in-bare-metal-kubernetes-271aab751fb8

# **Handledning**

## Installation och konfiguration

Installationen utg√•r ifr√•n det som publiceras p√• hemsidan och forts√§tter sen med det som framg√•r av artikeln 2 i listan. Vi att konfigurera kube-proxy med det som beh√∂vs samt konfigurera MetalLB med en loadbalancer med det IP adress-pool jag beh√∂ver.  

### Enable strict ARP mode

Om du anv√§nder kube-proxy i IPVS-l√§ge, m√•ste du sedan Kubernetes v1.14.2 aktivera strict ARP mode. Du kan uppn√• detta genom att redigera kube-proxy-konfigurationen i det aktuella klustret.

```bash 
kubectl get configmap kube-proxy -n kube-system -o yaml \
 |sed -e "s/strictARP: false/strictARP: true/" | kubectl apply -f - -n kube-system
```

> Obs! Detta inte beh√∂vs om du anv√§nder kube-router som service-proxy, eftersom det aktiverar strict ARP som standard.
> 

### Installation enligt metallb.universe.tf

Detta kommer att installera MetalLB i ditt kluster, under namespace `metallb-system`.

```bash
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.14.8/config/manifests/metallb-native.yaml
```

**Objekt i manifestet √§r:**

- `metallb-system/controller` deployment. Detta √§r den kluster√∂vergripande kontrollenheten som hanterar IP-adresstilldelningar.
- `metallb-system/speaker` daemonset. Detta √§r komponenten som anv√§nder det/de protokoll du v√§ljer f√∂r att g√∂ra tj√§nsterna n√•bara.
- Servicekonton f√∂r controller och speaker, tillsammans med de RBAC-beh√∂righeter som komponenterna har beh√∂vs f√∂r att fungera.

> Installationsmanifestet inkluderar inte n√•gon konfigurationsfil. MetalLB komponenter kommer att starta, men f√∂rblir inaktiva tills du b√∂rjar distribuera resurser.
> 

### Kontrollerar status p√• Metallb bas-objekt

Du kan kontrollera att de olika objekt i manifestet √§r ing√•ng utan fel.

```bash
kubectl -n metallb-system get pods
kubectl -n metallb-system get all
```

### Konfigurera LoadBalancer

Nu kan vi g√• vidare och konfigurera en adress-pool till v√•r loadbancer. H√∂r f√•r du anv√§nde det intervall som passar dig. Intervallet m√•ste vara reserverat och inte anv√§ndas av DHCP:en i din n√§t.

```yaml
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: first-pool
  namespace: metallb-system
spec:
  addresses:
  - 172.29.8.170-172.29.8.180           # Anv√§nd det som passar i din milj√∂
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: example
  namespace: metallb-system   
```

Spara detta i en yaml-fil och k√∂r sedan `kubectl apply -f <yaml-fil>` 

 

## Testa att LB g√∂r sitt

Vi kommer att installera tv√• enkla applikationer som vi sedan testar b√•de internt fr√•n Worker Nodes och externt klient via en webbl√§sare. Dessa applikationer kommer vi att se vilken pod inom klustret som svarar p√• fr√•gan, vilket hj√§lper oss att kontrollera att lastbalansering fungerar.

### App Demo1

Detta startar en l√§ttviktig webbserver som kommer att visa namnet p√• poden d√§r den k√∂rs.

```bash
kubectl create deployment demo1 --image=gcr.io/google-samples/hello-app:1.0 --replicas 3
kubectl expose deployment demo1 --type LoadBalancer --port 80 --target-port 8080
```

### App Demo2

```bash
kubectl create deployment demo2 --image=klimenta/serverip --replicas 6 --port 3000
kubectl expose deployment demo2 --type LoadBalancer --port 80 --target-port 3000
```

### Testa Demo1 & Demo1

Du kan k√∂ra f√∂ljande flera g√•nger i cli eller surfa in p√• den URL som visas.

```bash
# demo1
curl $(kubectl get svc demo1 |awk '/^demo1/  {print"http://"$4}'); \
echo "Testa sj√§lv nu fr√•n din webbklient:"; \
echo $(kubectl get svc demo1 |awk '/^demo1/  {print"http://"$4}')

# demo2
curl $(kubectl get svc demo2 |awk '/^demo2/  {print"http://"$4}'); \
echo "Testa sj√§lv nu fr√•n din webbklient:"; \
echo $(kubectl get svc demo2 |awk '/^demo2/  {print"http://"$4}')
```

### Test med loop

Vill du testa med loop i cli? Anv√§nd detta exempelvis.

```bash
for i in {1..5}
do
 curl $(kubectl get svc demo1 |awk '/^demo1/ {print"http://"$4}') ; echo "" 
done
```

## Rensa allt

Detta kan g√∂ras p√• flera olika s√§tt, men gemensamt f√∂r alla √§r anv√§ndningen av CLI-kommandona `kubectl delete service` och `kubectl delete deployment`.

```bash
for I in service/demo1 deployment.apps/demo1 service/demo2 deployment.apps/demo2 
do 
   kubectl delete $I
done
```
